{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10529, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Anti-National-Tweets-Classification/dataset/labelled/data_main.csv')\n",
    "data = data[pd.notnull(data['tweet'])]\n",
    "data_shuffled = pd.DataFrame()\n",
    "\n",
    "data = data.sample(data.shape[0])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tweet']\n",
    "Y = data['label']\n",
    "x_train,  x_test,y_train, y_test = train_test_split(X, Y, train_size=0.8,test_size=0.2, random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266    b want justice solution khalistan cant tollara...\n",
       "6512          road cant wait see everyone bootcamp nustar\n",
       "9444    happy work conference right mindset lead cultu...\n",
       "4993    great terry fox pathetic annoy khalistan refer...\n",
       "7733    enjoy moment everydaybeautiful zen mindfulness...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4228\n",
       "0.0    4195\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1089\n",
       "1.0    1017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8423, 10036)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8423, 10036)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791073124406457\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB().fit(x_train_tfidf, y_train)\n",
    "def Naive_Bayes_Classifier(x_test):\n",
    "    x_test_counts = count_vect.transform(x_test)\n",
    "    x_test_tfidf = tfidf_transformer.fit_transform(x_test_counts)\n",
    "    \n",
    "    predictions = naive_bayes.predict(x_test_tfidf)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "predictions = Naive_Bayes_Classifier(x_test)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886039886039886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amey\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train_tfidf, y_train)\n",
    "\n",
    "def Logistic_Regression_Classifier(x_test):\n",
    "    # all parameters not specified are set to their defaults\n",
    "    x_test_counts = count_vect.transform(x_test)\n",
    "    x_test_tfidf = tfidf_transformer.fit_transform(x_test_counts) \n",
    "    \n",
    "    predictions = logisticRegr.predict(x_test_tfidf)\n",
    "    \n",
    "    return(predictions)\n",
    "\n",
    "predictions = Logistic_Regression_Classifier(x_test)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9520417853751187\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "decisionTree = decisionTree.fit(x_train_tfidf, y_train)\n",
    "\n",
    "def Decision_Tree_Classifier(x_test):\n",
    "    x_test_counts = count_vect.transform(x_test)\n",
    "    x_test_tfidf = tfidf_transformer.fit_transform(x_test_counts)\n",
    "    \n",
    "    predictions = decisionTree.predict(x_test_tfidf)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "predictions = Decision_Tree_Classifier(x_test)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976258309591643\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "randomForest = randomForest.fit(x_train_tfidf, y_train)\n",
    "\n",
    "def Random_Forest_Classifier(x_test):\n",
    "    x_test_counts = count_vect.transform(x_test)\n",
    "    x_test_tfidf = tfidf_transformer.fit_transform(x_test_counts)\n",
    "    \n",
    "    predictions = randomForest.predict(x_test_tfidf)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "predictions = Random_Forest_Classifier(x_test)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watch Pokemon all day long! HAHA \n",
      "Classified as Negative\n"
     ]
    }
   ],
   "source": [
    "text = \"I watch Pokemon all day long! HAHA\"\n",
    "prediction = Naive_Bayes_Classifier([text])\n",
    "\n",
    "if(prediction == 1):\n",
    "    print(text,'\\nClassified as Positive')\n",
    "else:\n",
    "    print(text,'\\nClassified as Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logisticRegr, open('../Anti-National-Tweets-Classification/models/logistic_regression_model.pkl','wb')) \n",
    "pickle.dump(decisionTree, open('../Anti-National-Tweets-Classification/models/decision_tree_model.pkl','wb')) \n",
    "pickle.dump(randomForest, open('../Anti-National-Tweets-Classification/models/random_forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
