{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(column):\n",
    "    cleaned = []\n",
    "    for tweet in column:\n",
    "        tweet = tweet.encode().decode(encoding='UTF-8',errors='strict')\n",
    "        tweet = p.clean(tweet)\n",
    "        tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "        tweet = re.sub(r'^bRT[\\s]+', '', tweet)\n",
    "        tweet = re.sub(r'\\b(b\"RT)\\b', '', tweet)\n",
    "        tweet = re.sub(r\"\\b(b'RT)\\b\", '', tweet)\n",
    "        tweet = re.sub(r\"\\b(b')\\b\", '', tweet)\n",
    "        tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "        tweet = re.sub(r'#', '', tweet)\n",
    "        tweet = re.sub('[0-9]+', '', tweet)\n",
    "    \n",
    "        cleaned.append(tweet)\n",
    "    return pd.Series(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(words,tokenizer,stopwords_english):\n",
    "    \n",
    "    tweet_clean = []\n",
    "\n",
    "    for word in words: # Go through every word in your tokens list\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation and len(word) > 3):  # remove punctuation\n",
    "            tweet_clean.append(word)\n",
    "    \n",
    "    return tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text,lemmatizer,w_tokenizer):\n",
    "      return [(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(data):\n",
    "    \n",
    "    processed = []\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    w_tokenizer =  TweetTokenizer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    for tweet in data:\n",
    "        tweet = tweet.replace('\\d+', '')\n",
    "\n",
    "        tweet = tweet.lower()    \n",
    "\n",
    "        \n",
    "        lemmatized_tweet = lemmatize_text(tweet,lemmatizer,w_tokenizer)\n",
    "        \n",
    "        final = remove_punctuations(lemmatized_tweet,w_tokenizer,stopwords_english)\n",
    "        \n",
    "        processed.append(final)\n",
    "        \n",
    "    return (processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../khalistan.csv')\n",
    "cleaned_csv = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337     b'RT @Ravneet85005514: The so-called \"pure\" co...\n",
       "4156    b'Great #TerryFox BUT\\nPathetic @CBCTerry Is A...\n",
       "3467    b'RT @Ashakaur20: In 1941 Sikhs had no special...\n",
       "329     b'Mr. #Pannun, this #door to door campaign is ...\n",
       "1470    b'Indian government throw poor farmers at the ...\n",
       "1743    b'Stop #Modi From seizing the Lands of #Punjab...\n",
       "3688    b'Great #TerryFox BUT Pathetic @CBCTerry concl...\n",
       "1773    b'Lets raisebour voices together and Stop #Mod...\n",
       "2454    b'RT @KanchanGupta: Petition in Delhi High Cou...\n",
       "1145    b\"#SFJ  \\n#Khalistan\\n#GheraoModi\\n#BharatBand...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "337     b'RT @Ravneet85005514: The so-called \"pure\" co...\n",
       "4156    b'Great #TerryFox BUT\\nPathetic @CBCTerry Is A...\n",
       "3467    b'RT @Ashakaur20: In 1941 Sikhs had no special...\n",
       "329     b'Mr. #Pannun, this #door to door campaign is ...\n",
       "1470    b'Indian government throw poor farmers at the ...\n",
       "1743    b'Stop #Modi From seizing the Lands of #Punjab...\n",
       "3688    b'Great #TerryFox BUT Pathetic @CBCTerry concl...\n",
       "1773    b'Lets raisebour voices together and Stop #Mod...\n",
       "2454    b'RT @KanchanGupta: Petition in Delhi High Cou...\n",
       "1145    b\"#SFJ  \\n#Khalistan\\n#GheraoModi\\n#BharatBand...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     : The so-called \"pure\" country called Pakista...\n",
      "1    Great BUT\\nPathetic Is Annoyed At Posters At S...\n",
      "2     : In Sikhs had no special claim to the undivi...\n",
      "3    Mr. , this to door campaign is going to be a s...\n",
      "4    Indian government throw poor farmers at the me...\n",
      "5    Stop From seizing the Lands of \\nits time to t...\n",
      "6    Great BUT Pathetic concludes No Support For By...\n",
      "7    Lets raisebour voices together and Stop From s...\n",
      "8     : Petition in Delhi High Court against whose ...\n",
      "9    b\" \\n\\n\\n\\nYou Cannot Take the Land of the Far...\n",
      "dtype: object\n",
      "0     : The so-called \"pure\" country called Pakista...\n",
      "1    Great BUT\\nPathetic Is Annoyed At Posters At S...\n",
      "2     : In Sikhs had no special claim to the undivi...\n",
      "3    Mr. , this to door campaign is going to be a s...\n",
      "4    Indian government throw poor farmers at the me...\n",
      "5    Stop From seizing the Lands of \\nits time to t...\n",
      "6    Great BUT Pathetic concludes No Support For By...\n",
      "7    Lets raisebour voices together and Stop From s...\n",
      "8     : Petition in Delhi High Court against whose ...\n",
      "9    b\" \\n\\n\\n\\nYou Cannot Take the Land of the Far...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cleaned_tweets = clean_tweet(trial['tweet'])\n",
    "print(cleaned_tweets)\n",
    "# cleaned_csv['tweets_cleaned'] = cleaned_tweets\n",
    "# cleaned_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = preprocess_tweet(cleaned_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so-called',\n",
       " 'pure',\n",
       " 'country',\n",
       " 'called',\n",
       " 'pakistan',\n",
       " 'killing',\n",
       " 'murdering',\n",
       " 'blasting',\n",
       " 'commuting',\n",
       " 'inhuman',\n",
       " 'atrocity',\n",
       " 'thei']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['so-called',\n",
       " 'pure',\n",
       " 'country',\n",
       " 'called',\n",
       " 'pakistan',\n",
       " 'killing',\n",
       " 'murdering',\n",
       " 'blasting',\n",
       " 'commuting',\n",
       " 'inhuman',\n",
       " 'atrocity',\n",
       " 'thei']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.DataFrame(columns = ['tweets','hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets[‘hashtag’] = tweets[‘tweet_text’].apply(lambda x: re.findall(r”#(\\w+)”, x))\n",
    "processed_data['hashtags'] = data.tweet.apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "processed_data['tweets'] = pd.Series(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
