{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_Data_Downloader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        consumer_key = '1aWY7LUDcpfRinxw31OFOcbzI'\n",
    "        consumer_secret = 'NJ0DllMlhoSrWazB2BtAVO21K5rhKKnZzAGL00WmZ1M1YSNHq8'\n",
    "        access_token = '2904265662-Zv1kX1y1k1Nky8dpMmKJJzrAQLYdQVdDLNwgiYs'\n",
    "        access_token_secret = '7dofFG4oUInt6L7vPClauLz7jJMVZvxbuo9ta9Ec4HJuC'\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self.api = tweepy.API(auth, wait_on_rate_limit=True)        \n",
    "        \n",
    "        \n",
    "    def get_data(self, hashtag, since):\n",
    "        row = {}\n",
    "        data = pd.DataFrame(columns= ['user_id','created_at','tweet','hashtags',\n",
    "                                    'retweet_count','favourite_count', 'tweet_url'])\n",
    "\n",
    "        for tweet in tweepy.Cursor(self.api.search, q=hashtag, lang=\"en\", since=since).items():\n",
    "            print (\"\\n\", tweet.created_at, tweet.text.encode('utf8'))\n",
    "            row.update({'user_id' : tweet.author.screen_name.encode('utf8')})\n",
    "            row.update({'created_at' : tweet.created_at})    \n",
    "            row.update({'tweet' : tweet.text.encode('utf8')})\n",
    "            row.update({'hashtags' : tweet.entities.get('hashtags')})\n",
    "            row.update({'retweet_count' : tweet.retweet_count})\n",
    "            row.update({'favourite_count' : tweet.favorite_count})\n",
    "            row.update({'tweet_url' : tweet.entities.get('url')})\n",
    "            row.update({'tweet_url' : tweet.entities['urls']})\n",
    "            \n",
    "            data = data.append(row, ignore_index= True)\n",
    "        \n",
    "        name = hashtag.split(\"#\")[1]\n",
    "        name = \"dataset/raw_dataset/\"+name+\"_new.csv\"\n",
    "        data.to_csv(name)\n",
    "            \n",
    "            \n",
    "    def read_data(self, hashtag):\n",
    "        name = hashtag.split(\"#\")[1]\n",
    "        name = \"dataset/raw_dataset/\"+name+\".csv\"\n",
    "        df = pd.read_csv(name)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdd = Twitter_Data_Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = \"#Referendum2020\"\n",
    "tdd.get_data(hashtag, \"2019-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tdd.read_data(hashtag)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
